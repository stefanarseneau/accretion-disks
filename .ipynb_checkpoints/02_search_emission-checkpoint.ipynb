{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba1a8400-676a-4eb0-9292-f27d9ac96bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not find pickled WD models\n",
      "/Users/vedantchandra/0_research/01_sdss5/006_build_corv/data/comm_cat/\n",
      "star and exposure catalogs not found! check paths and run make_catalogs() if you want to use sdss functionality. otherwise ignore.\n"
     ]
    }
   ],
   "source": [
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('../corv-dev/corv/src')\n",
    "import corv\n",
    "\n",
    "#to import SDSS-V data\n",
    "import fsspec\n",
    "import requests\n",
    "import aiohttp\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6c04c23-6a09-4303-b12e-1317b40782a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in SDSS-V access tokens and the Gaia crossmatch table\n",
    "with open('creds.txt') as f:\n",
    "    creds = f.read().splitlines()\n",
    "    \n",
    "catalog = Table.read('data/SDSS_V_Gaia_xmatch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "662ef810-b123-447d-87ff-78a1766fbf23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spec-101748-59846-27021597834828397.fits'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog[0]['spec_file']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325b0c51-49c1-42ea-9f1b-099ba9337414",
   "metadata": {},
   "source": [
    "For some reason, Nicole's code for programmatically accessing SDSS-V data doesn't work for my machine. My strategy is going to be splitting the sample into batches of 200-300 spectra, analyzing each spectrum, deleting them from my computer, and downloading another batch. The emission line strategy is going to be:\n",
    "1. Fit two Voight profiles with negative amplitude and two with positive amplitude\n",
    "2. Plot the mean amplitude of the two positive guys\n",
    "3. Look for a good bifurcation point\n",
    "\n",
    "SDSS-V data is stored at:\n",
    "https://data.sdss5.org/sas/sdsswork/bhm/boss/spectro/redux/v6_1_0/spectra\n",
    "\n",
    "\n",
    "The spectra directory is organized as follows:\n",
    "\n",
    "    - Plate number (ex. 15000/)\n",
    "        - MJD (ex. 15000/59146/)\n",
    "            - spectum fits file labeled by spec-PLATE-MJD-CATALOGID.fits (ex. spec-015000-59146-4375786564.fits)\n",
    "            - the most recent spAll file also has a SPEC_FILE column which gives the name of the fits file\n",
    "\n",
    "Download and open spAll-master.fits\n",
    "\n",
    "    - This is a table that has information about objects observed in the plate and FPS programs\n",
    "    \n",
    "    \n",
    "Confirmed accretion disk: https://data.sdss5.org/sas/sdsswork/bhm/boss/spectro/redux/v6_1_0/spectra/full/015333/59306/spec-015333-59306-5276309279.fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c529fe98-eb42-443e-82e0-68c57e9713b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñç                                                                            | 80/13112 [01:51<5:58:04,  1.65s/it]"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "import tqdm\n",
    "\n",
    "from lmfit.models import Model, ConstantModel, VoigtModel\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "session = requests.Session()\n",
    "session.auth = (creds[0],creds[1])\n",
    "\n",
    "\n",
    "def download_spectrum(rows, outfile = 'tempfiles/'):    \n",
    "    # use the requests package to download the fits file of a given row quickly\n",
    "    plate = row['spec_file'].split('-')[1]\n",
    "    mjd = row['spec_file'].split('-')[2]\n",
    "    file = row['spec_file']\n",
    "    \n",
    "    filepath = 'https://data.sdss5.org/sas/sdsswork/bhm/boss/spectro/redux/v6_1_0/spectra/full/{}/{}/{}'.format(plate, mjd, file)\n",
    "    \n",
    "    with open('tempfiles/{}'.format(row['spec_file']), 'wb') as f:\n",
    "        f.write(session.get(filepath).content)\n",
    "        \n",
    "    file = fits.open('tempfiles/{}'.format(row['spec_file']))\n",
    "    \n",
    "    os.system('rm tempfiles/*')\n",
    "            \n",
    "    return file\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def analysis_function(file, ii): \n",
    "    # first, get the relevant data from the file\n",
    "    wl = 10**file[1].data['LOGLAM']\n",
    "    fl = file[1].data['FLUX']\n",
    "    ivar = file[1].data['IVAR']\n",
    "    \n",
    "    # continuum normalize using the function supplied by corv\n",
    "    wl, fl, ivar = corv.utils.continuum_normalize(wl, fl, ivar)\n",
    "    \n",
    "    # outmask masks everything outside of Ha, inmask masks the very centroid of the line\n",
    "    outmask = (6464 < wl) * (wl < 6664)\n",
    "    inmask = (6561 < wl) * (wl < 6569)\n",
    "    \n",
    "    # fit the first model using only the wings of the function\n",
    "    mask = outmask * ~inmask\n",
    "    \n",
    "    # the first model is restricted to have amplitude < 0\n",
    "    model = ConstantModel() - VoigtModel(prefix = 'down')\n",
    "    model.set_param_hint('downamplitude', value = 15, min = 0)\n",
    "    model.set_param_hint('downsigma', value = 15, min = 0)\n",
    "    model.set_param_hint('downcenter', value =  6564.61, min = 6534.61, max =  6594.61)\n",
    "    \n",
    "    base_result = model.fit(fl[mask], x=wl[mask], amp=5, cen=5, wid=1, nan_policy='omit')\n",
    "    \n",
    "    # for the second model, lock in the already-fit parameters for the first model and do not allow them to vary\n",
    "    for name in (model.param_names):\n",
    "        val = base_result.params[name].value\n",
    "        model.set_param_hint(name, value = val, vary = False)\n",
    "        \n",
    "    # change the mask to fit all wavelengths around the Ha line\n",
    "    mask = outmask\n",
    "        \n",
    "    # the second Voigt profile can have positive or negative amplitude\n",
    "    model += VoigtModel(prefix = 'up')\n",
    "    model.set_param_hint('upamplitude', value = 15, max = 100)\n",
    "    model.set_param_hint('upsigma', value = 15, min = 0, max = 100)\n",
    "    model.set_param_hint('upcenter', value =  6564.61, min =  6556.61, max =  6574.61)\n",
    "    \n",
    "    result = model.fit(fl[mask], x=wl[mask], amp=5, cen=5, wid=1)\n",
    "    \n",
    "    # this can be deleted later\n",
    "    ratio = result.params['upamplitude'].value / result.params['downamplitude'].value\n",
    "    amp = result.params['upamplitude'].value\n",
    "    sigma = result.params['upsigma'].value\n",
    "    \n",
    "    # save a plot of the fitted model\n",
    "    plt.figure(figsize = (10,10))\n",
    "    \n",
    "    plt.plot(wl[mask], fl[mask])\n",
    "    plt.plot(wl[mask], result.best_fit, '-', label='best fit')\n",
    "    \n",
    "    plt.savefig('./plots/fits/{}'.format(ii))\n",
    "    \n",
    "    plt.close()\n",
    "    \n",
    "    return [base_result, result]\n",
    "    \n",
    "\n",
    "# run the analysis function on each row in the catalog\n",
    "res = []\n",
    "for i, row in tqdm.tqdm(enumerate(catalog), total = len(catalog)):\n",
    "    # select the rows that make up each batch and download their spectra\n",
    "    file = download_spectrum(row)\n",
    "    \n",
    "    # perform the analysis\n",
    "    res.append(analysis_function(file, i))\n",
    "    \n",
    "    \n",
    "    \n",
    "# this is supposed to be the parallelizaiton code, but idk if it works right now\n",
    "#def analyze(ii):\n",
    "#    file = download_spectrum(catalog[ii])\n",
    "#    return analysis_function(file, ii)\n",
    "#    \n",
    "#if __name__ == \"__main__\":\n",
    "#    tasks = range(len(catalog))\n",
    "#    pool = Pool(processes=4)\n",
    "#    \n",
    "#    mapped_values = list(tqdm.tqdm(pool.imap_unordered(analyze, tasks), total=len(tasks)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82a1f1b-dbb4-41e2-9f68-51e0cad47c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa5d2d5-6c89-4cd3-96ed-191fc63e4fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = fits.open('spec-015333-59306-5276309279.fits')\n",
    "\n",
    "ref = analysis_function(file,  100)\n",
    "res.append(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5efe90-6a5b-47e6-8c62-46fffeed2c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4f9ec8-3245-49b1-8de3-e062305488c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = res\n",
    "res = np.array(temp).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f1d782-28a7-4f5f-a47d-dc14ce790022",
   "metadata": {},
   "outputs": [],
   "source": [
    "upamps = np.array([res[1][i].params['upamplitude'].value for i in range(len(res[0]))])\n",
    "dnamps = np.array([res[1][i].params['downamplitude'].value for i in range(len(res[0]))])\n",
    "\n",
    "upsigma = np.array([res[1][i].params['upsigma'].value for i in range(len(res[0]))])\n",
    "dnsigma = np.array([res[1][i].params['downsigma'].value for i in range(len(res[0]))])\n",
    "\n",
    "upcen = np.array([res[1][i].params['upcenter'].value for i in range(len(res[0]))])\n",
    "dncen = np.array([res[1][i].params['downcenter'].value for i in range(len(res[0]))])\n",
    "\n",
    "chisqr1 = np.array([res[0][i].redchi for i in range(len(res[0]))])\n",
    "chisqr2 = np.array([res[1][i].redchi for i in range(len(res[0]))])\n",
    "\n",
    "d_chisqr = np.array([chisqr2[i] - chisqr1[i] for i in range(len(chisqr1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99593526-95ad-4dff-a36d-77933413e48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ampratio = upamps / dnamps\n",
    "sigratio = upsigma / dnsigma\n",
    "cenratio = np.abs(upcen - dncen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e0cf66-3e7d-468f-bccd-425a4c8719f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(cenratio < 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144cdda6-7e1a-45fd-8384-9eb23d1ee419",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(upamps > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c11e489-c31a-4bd3-9412-5f26026fd07e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
